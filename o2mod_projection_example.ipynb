{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca0592ae-980e-4ff1-937a-6a004ec8a0f6",
   "metadata": {},
   "source": [
    "# North Atlantic O2 projection\n",
    "    - 3D isopycnal version\n",
    "    - This script takes the output of the o2mod_example_CV_v2.ipynb\n",
    "    - O2 is estimated as a function of T, S, long, lat, year, month (below 100m, month is always March = 2)\n",
    "    - year is measured since 1965-01\n",
    "    - Estimation methods include Neural Network and Random Forest Regression\n",
    "    - Specify the ML you want to use, and the range of years to calculate the O2 field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2dec558-ed3b-46b4-8916-3152fb8a6c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import sklearn as skl\n",
    "import gsw\n",
    "import joblib\n",
    "import os\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa8a8079-9cb6-4373-b697-ca2a6d3649a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the ML model & select the basin\n",
    "model = 'IPSL-CM6A-LR'\n",
    "Basin = 1\n",
    "#filename = f'RF_model_{model}.sav'\n",
    "MLname = 'SNN'\n",
    "filename = f'sNN_model_{model}.sav'\n",
    "#filename = f'dNN_model_{model}.sav'\n",
    "#\n",
    "! mkdir -p temp\n",
    "! mkdir -p output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a3ed930-0278-4b84-976d-5d1a74ecce10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/ito/miniconda3/envs/calc2/lib/python3.8/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator MLPRegressor from version 1.2.1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/glade/work/ito/miniconda3/envs/calc2/lib/python3.8/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator GridSearchCV from version 1.2.1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "MLmodel = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9119f58b-f2a6-492c-ae13-588a61eb4a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the mean and standard deviation values\n",
    "dataref = np.load(f'ML_params_{model}.npz')#, Xm=Xm, Xstd=Xstd, ym=ym, ystd=ystd)\n",
    "Xm=dataref['Xm']\n",
    "Xstd=dataref['Xstd']\n",
    "ym=dataref['ym']\n",
    "ystd=dataref['ystd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc861e73-9cf6-4b43-9ee7-e8722f60104e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the input data for projection\n",
    "# Define the directory where the CMIP6 data for the model is stored\n",
    "dir = '/glade/campaign/univ/ugit0034/cmip6/' + model + '/'\n",
    "\n",
    "# Open the dataset for oxygen concentration for the specified model and time range\n",
    "ds0 = xr.open_dataset(dir + 'o2_' + model + '_196501-201412.nc')\n",
    "\n",
    "# Open the dataset for sea surface salinity for the specified model and time range\n",
    "ds1 = xr.open_dataset(dir + 'so_' + model + '_196501-201412.nc')\n",
    "\n",
    "# Open the dataset for sea surface temperature for the specified model and time range\n",
    "ds2 = xr.open_dataset(dir + 'thetao_' + model + '_196501-201412.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6f54f70-e462-483b-a4fd-46108f6cc5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the dataset for the basin mask\n",
    "dsm = xr.open_dataset('/glade/campaign/univ/ugit0034/cmip6/basin_mask_01.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85b641da-55a3-48c4-b739-1f800039cf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get longitude values from the ds0 dataset and convert to a NumPy array\n",
    "x = ds0.lon.to_numpy()\n",
    "\n",
    "# Get latitude values from the ds0 dataset and convert to a NumPy array\n",
    "y = ds0.lat.to_numpy()\n",
    "\n",
    "# Create a 1D array of longitude values ranging from 0 to 359 with a step size of 1\n",
    "xi = np.arange(0, 360, 1)\n",
    "\n",
    "# Create a 1D array of latitude values ranging from 0 to 179 with a step size of 1\n",
    "yi = np.arange(0, 180, 1)\n",
    "\n",
    "# Create a 2D grid of longitude and latitude values using meshgrid\n",
    "xx, yy = np.meshgrid(x, y)\n",
    "\n",
    "# Create a 2D grid of longitude and latitude values using meshgrid for the new coordinates\n",
    "xxi, yyi = np.meshgrid(xi, yi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff62e6a7-cf0f-4cad-b11d-547eddf3145e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the basin mask from the dsm dataset\n",
    "mask = dsm.basin_mask\n",
    "\n",
    "# Extract the depth values for oxygen concentration from the o2 dataset and convert to NumPy array\n",
    "zmod = ds0.depth.to_numpy()\n",
    "\n",
    "# Extract the depth values for the basin mask from the mask dataset and convert to NumPy array\n",
    "zmask = mask.depth.to_numpy()\n",
    "\n",
    "# select a basin mask at the model depth levels\n",
    "ma = dsm.basin_mask.sel(depth=zmod,method='nearest').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67a3b878-7364-421a-8661-192f3c15cd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply basin mask \n",
    "def apply_basinmask(datain,basin):\n",
    "    #dataout=np.where((ma==basin)&(yy>0),datain,np.nan)\n",
    "    dataout=np.where((ma==basin)&(yy>0),datain,np.nan)\n",
    "    return dataout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5619ed18-93b9-4a2a-aa5e-cfc1964d22dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(data,w):\n",
    "    weight=np.ones(w)/w\n",
    "    smooth_data=np.convolve(data, weight, mode='same')\n",
    "    return smooth_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63ccfa6c-e2b9-46fd-9781-2ee62f1064ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get input data from full model\n",
    "def get_inputdata(zlev,it):\n",
    "    # Open the dataset for sea surface salinity for the specified model and time range\n",
    "    ds1 = xr.open_dataset(dir + 'so_' + model + '_196501-201412.nc')\n",
    "    # Open the dataset for sea surface temperature for the specified model and time range\n",
    "    ds2 = xr.open_dataset(dir + 'thetao_' + model + '_196501-201412.nc')\n",
    "    #\n",
    "    soa=ds1.so.isel(time=it).interp(depth=zlev).to_numpy().squeeze()\n",
    "    toa=ds2.thetao.isel(time=it).interp(depth=zlev).to_numpy().squeeze()\n",
    "    return soa,toa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23b08ef5-ffc0-4e72-ae09-abba38942977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data matrix\n",
    "def gen_datamatrix(xi,yi,x1,x2,it,xind,yind):\n",
    "    X1 = x1.flatten() # \n",
    "    X2 = x2.flatten() #\n",
    "    mo = it % 12\n",
    "    yr = (it - mo) / 12\n",
    "    X5 = np.ones(np.shape(x1))*yr\n",
    "    X6 = np.ones(np.shape(x1))*mo\n",
    "    X5 = X5.flatten()\n",
    "    X6 = X6.flatten()\n",
    "    X3 = xind.flatten() # lon\n",
    "    X4 = yind.flatten() # lat\n",
    "    xind0 = xind.flatten()\n",
    "    yind0 = yind.flatten()\n",
    "    # remove nan\n",
    "    dd = X1+X2\n",
    "    X11=X1[np.isnan(dd)==False]\n",
    "    X21=X2[np.isnan(dd)==False]\n",
    "    X31=X3[np.isnan(dd)==False]\n",
    "    X41=X4[np.isnan(dd)==False]\n",
    "    X51=X5[np.isnan(dd)==False]\n",
    "    X61=X6[np.isnan(dd)==False]\n",
    "    Xind = xind0[np.isnan(dd)==False]\n",
    "    Yind = yind0[np.isnan(dd)==False]\n",
    "    # Normalize data\n",
    "    # Create a 2D array 'X' containing dsa1, dta1, xx1, yy1, yr1, mn1 as its rows\n",
    "    # generate data matrix and standardize it\n",
    "    X = np.array([X11, X21, X31, X41, X51, X61])\n",
    "    Xa = (X.T - Xm)/Xstd\n",
    "    Nsample = np.size(X11)\n",
    "    #print(Nsample)\n",
    "    return Xa,Xind,Yind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f6121af-bd91-444c-9242-4e8ad120bd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_yearly(year):\n",
    "    Nx=np.size(x)\n",
    "    Ny=np.size(y)\n",
    "    zlev_arr=np.array([zlev])\n",
    "    o2est2=np.zeros((12,1,Ny,Nx))\n",
    "    xind,yind=np.meshgrid(np.arange(0,Nx,1),np.arange(0,Ny,1))\n",
    "    if year%10 == 5:\n",
    "        print('year = '+str(year))\n",
    "    t=np.arange(str(year)+'-01',str(year+1)+'-01',dtype='datetime64[M]')\n",
    "    for month in range(12):\n",
    "        it = month+(year-1965)*12\n",
    "        soa,toa = get_inputdata(zlev,it)\n",
    "        # apply mask\n",
    "        soa=apply_basinmask(soa,Basin)\n",
    "        toa=apply_basinmask(toa,Basin)\n",
    "        # generate data matrix\n",
    "        Xa,xi,yi=gen_datamatrix(soa,toa,xx,yy,it,xind,yind)\n",
    "        temp = np.shape(Xa)\n",
    "        Nsample=temp[0]\n",
    "        # projection\n",
    "        out = reg.predict(Xa)\n",
    "        # map it back to lon-lat grid\n",
    "        temp = np.nan*np.zeros((Ny,Nx))\n",
    "        for n in range(Nsample):\n",
    "            temp[yi[n],xi[n]]=out[n]\n",
    "        o2est2[month,0,:,:] = temp*ystd + ym\n",
    "    da1=xr.DataArray(data=o2est2,name='o2est',dims=['time','depth','lat','lon'],\n",
    "                 coords={'time':t,'depth':zlev_arr,'lat':y,'lon':x})\n",
    "    ds=da1.to_dataset()\n",
    "    ds.to_netcdf('temp/o2est_'+str(year)+'.nc')\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97d6908f-8a77-4f76-a7cc-de5c6aa40a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating 0.0m\n",
      "year = 1965year = 1975\n",
      "\n",
      "year = 1985\n",
      "year = 1995\n",
      "year = 2005\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "calculating 10.0m\n",
      "year = 1975year = 1965\n",
      "\n",
      "year = 1985\n",
      "year = 1995\n",
      "year = 2005\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "calculating 20.0m\n",
      "year = 1975year = 1965\n",
      "\n",
      "year = 1985\n",
      "year = 1995\n",
      "year = 2005\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "calculating 30.0m\n",
      "year = 1975year = 1965\n",
      "\n",
      "year = 1985\n",
      "year = 1995\n",
      "year = 2005\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "calculating 50.0m\n",
      "year = 1975year = 1965\n",
      "\n",
      "year = 1985\n",
      "year = 1995\n",
      "year = 2005\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "calculating 75.0m\n",
      "year = 1965year = 1975\n",
      "\n",
      "year = 1985\n",
      "year = 1995\n",
      "year = 2005\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "calculating 100.0m\n",
      "year = 1975year = 1965\n",
      "\n",
      "year = 1985\n",
      "year = 1995\n",
      "year = 2005\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "calculating 125.0m\n",
      "year = 1975year = 1965\n",
      "\n",
      "year = 1985\n",
      "year = 1995\n",
      "year = 2005\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "calculating 150.0m\n",
      "year = 1975year = 1965\n",
      "\n",
      "year = 1985\n",
      "year = 1995\n",
      "year = 2005\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "calculating 200.0m\n",
      "year = 1975year = 1965\n",
      "\n",
      "year = 1985\n",
      "year = 1995\n",
      "year = 2005\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "calculating 250.0m\n",
      "year = 1975year = 1965\n",
      "\n",
      "year = 1985\n",
      "year = 1995\n",
      "year = 2005\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "calculating 300.0m\n",
      "year = 1965year = 1975\n",
      "\n",
      "year = 1985\n",
      "year = 1995\n",
      "year = 2005\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "calculating 400.0m\n",
      "year = 1965year = 1975\n",
      "\n",
      "year = 1985\n",
      "year = 1995\n",
      "year = 2005\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "calculating 500.0m\n",
      "year = 1975year = 1965\n",
      "\n",
      "year = 1985\n",
      "year = 1995\n",
      "year = 2005\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "calculating 600.0m\n",
      "year = 1975year = 1965\n",
      "\n",
      "year = 1985\n",
      "year = 1995\n",
      "year = 2005\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "calculating 700.0m\n",
      "year = 1975year = 1965\n",
      "\n",
      "year = 1985\n",
      "year = 1995\n",
      "year = 2005\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "calculating 800.0m\n",
      "year = 1965year = 1975\n",
      "\n",
      "year = 1985\n",
      "year = 1995\n",
      "year = 2005\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "calculating 900.0m\n",
      "year = 1965year = 1975\n",
      "\n",
      "year = 1985\n",
      "year = 1995\n",
      "year = 2005\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "calculating 1000.0m\n",
      "year = 1975year = 1965\n",
      "\n",
      "year = 1985\n",
      "year = 1995\n",
      "year = 2005\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "zlevels = zmod.copy()\n",
    "yrs=np.arange(1965,2015,1)\n",
    "#\n",
    "# reconstruction in parallel mode\n",
    "#\n",
    "reg=MLmodel\n",
    "x = ds0.lon.to_numpy()\n",
    "y = ds0.lat.to_numpy()\n",
    "#\n",
    "for zlev_cnt,zlev in enumerate(zlevels):\n",
    "    print(f'calculating {zlev}m')\n",
    "    maz = dsm.basin_mask.interp(depth=zlev).to_numpy()\n",
    "    #kind=[idx for idx,elem in enumerate(Z) if elem==zlev]\n",
    "    #maz=np.squeeze(ma[kind,:,:])\n",
    "    os.system('rm temp/*.nc')\n",
    "    #\n",
    "    if __name__ == '__main__':\n",
    "        with Pool(10) as p:\n",
    "            print(p.map(map_yearly, yrs))\n",
    "    #\n",
    "    # save the result as a netCDF file\n",
    "    #\n",
    "    dtemp=xr.open_mfdataset('temp/o2est*.nc')\n",
    "    dtemp.to_netcdf(f'output/O2_'+model+'_z'+str(int(zlev))+'.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3534faed-4168-4e28-8333-2bc96ee9ec63",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtemp.to_netcdf(f'output/O2_'+model+'_z'+str(int(zlev))+'.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0798c6b-9970-4c9b-8238-222e6380767e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=xr.open_mfdataset(f'output/O2_{model}_z*')\n",
    "ds.to_netcdf(f'output/O2_{model}_{MLname}_monthly.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd64a58-0b55-4d17-bdea-cfe3656c5065",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "calc2",
   "language": "python",
   "name": "calc2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
