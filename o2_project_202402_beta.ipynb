{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49353156-83a0-4d0c-b13c-e71c192b1500",
   "metadata": {},
   "source": [
    "# O2 gapfill projection\n",
    "    - Needs to enter a 6 digit input parameter as follows : \n",
    "    - First digit = Algorithm type (1=RF, 2=NN)\n",
    "    - Second digit = Data Source (1=Ship only, 2=Ship+Argo)\n",
    "    - Third digit = Ocean basin (1=Atlantic, 2=Pacific, 3=Indian, 4=Southern, 5=Arctic)\n",
    "    - Fourth digit = T/S data source (1=EN4)\n",
    "    - Fifth digit = predictor variable set (1=default)\n",
    "    - Sixth digit = hyperparameter set (1=default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6bc1ecb-a8dd-41b0-a663-4ce4286e87fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import sklearn as skl\n",
    "import gsw\n",
    "import cartopy.crs as ccrs\n",
    "from scipy.interpolate import interp1d\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import joblib\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e55c7b99-e574-49a4-bfb6-1ff742942808",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# version information\n",
    "#\n",
    "ver = '1.2.1.1.1.1'\n",
    "# \n",
    "# The version information will determine which basin / algorithm will be used to calculate the O2 maps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af30cdb5-18a7-4749-8407-022eff6dd74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forst algorithm will be used.\n",
      "Ship-based and Argo-O2 data will be used. end_year = 2021\n",
      "Atlantic Ocean will be mapped\n",
      "EN4 dataset will be used for T/S input. \n",
      "Predictor variables include T, S, lon, lat, depth (pressure), year, month\n",
      "Hyperparameter set is optimized via K-fold CV\n"
     ]
    }
   ],
   "source": [
    "selection = ver.split('.')\n",
    "basin = ['Atlantic','Pacific','Indian','Southern','Arctic']\n",
    "#\n",
    "if selection[0] == '1':\n",
    "    print('Random Forst algorithm will be used.')\n",
    "    alg = 'RF'\n",
    "elif selection[0] == '2':\n",
    "    print('Neural Network algorithm will be used.')\n",
    "    alg = 'NN'\n",
    "else:\n",
    "    print('error - incorrect algorithm type')\n",
    "#\n",
    "if selection[1] == '1':\n",
    "    print('Ship-based O2 data will be used. end_year = 2011')\n",
    "    endyear=2011\n",
    "elif selection[1] == '2':\n",
    "    print('Ship-based and Argo-O2 data will be used. end_year = 2021')\n",
    "    endyear=2021\n",
    "else:\n",
    "    print('error - incorrect input data type')\n",
    "#\n",
    "if selection[2] == '1':\n",
    "    print(basin[int(selection[2])-1]+' Ocean will be mapped')\n",
    "elif selection[2] == '2':\n",
    "    print(basin[int(selection[2])-1]+' Ocean will be mapped')\n",
    "elif selection[2] == '3':\n",
    "    print(basin[int(selection[2])-1]+' Ocean will be mapped')\n",
    "elif selection[2] == '4':\n",
    "    print(basin[int(selection[2])-1]+' Ocean will be mapped')\n",
    "elif selection[2] == '5':\n",
    "    print(basin[int(selection[2])-1]+' Ocean will be mapped')\n",
    "else:\n",
    "    print('error - incorrect O2 data type')\n",
    "#\n",
    "if selection[3] == '1':\n",
    "    print('EN4 dataset will be used for T/S input. ')\n",
    "else:\n",
    "    print('error - incorrect T/S data type')\n",
    "#\n",
    "if selection[4] == '1':\n",
    "    print('Predictor variables include T, S, lon, lat, depth (pressure), year, month')\n",
    "else:\n",
    "    print('error - incorrect predictor variable type')\n",
    "#\n",
    "if selection[5] == '1':\n",
    "    print('Hyperparameter set is optimized via K-fold CV')\n",
    "else:\n",
    "    print('error - incorrect hyperparameter type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f352f89b-2c15-455e-a762-f9bbcebac44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input and output folders\n",
    "#\n",
    "os.system('echo $USER > userid')\n",
    "usrid=np.genfromtxt('userid',dtype='<U32')\n",
    "os.system('rm userid')\n",
    "diro = '/glade/derecho/scratch/'+str(usrid)+'/WOD18_OSDCTD/'\n",
    "dirf = '/glade/campaign/univ/ugit0034/EN4/L09_20x180x360/'\n",
    "dirin = '/glade/campaign/univ/ugit0034/WOD18_OSDCTD/'\n",
    "fosd='_1x1bin_osd_'\n",
    "fctd='_1x1bin_ctd_'\n",
    "fmer='_1x1bin_osdctd_'\n",
    "var=['o2','TSN2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "397f31ef-e8e8-459a-8016-a11e1de74de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain vertical grid\n",
    "ds=xr.open_dataset(dirin+var[0]+fmer+str(1965)+'.nc')\n",
    "Z=ds.depth.to_numpy()\n",
    "Nz=np.size(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16e94634-89c6-47cc-b8a3-cfbd7adb4e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select analysis period\n",
    "# do not change the start year from 1965 (this is when Carpenter 1965 established modern Winkler method)\n",
    "yrs=np.arange(1965,endyear,1)\n",
    "t=np.arange('1965-01',str(endyear)+'-01',dtype='datetime64[M]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02da61a5-d5f2-4782-9fa7-2a25aa162008",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/glade/campaign/univ/ugit0034/ML4O2_results/algorithm_v1.2.1.1.1.1.sav'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m dirout\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/glade/campaign/univ/ugit0034/ML4O2_results/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m MLmodel \u001b[38;5;241m=\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirout\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43malgorithm_v\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mver\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.sav\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# read in additional parameters\u001b[39;00m\n\u001b[1;32m      4\u001b[0m params \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(dirout\u001b[38;5;241m+\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mML_params_v\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.npz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4o2_v2/lib/python3.12/site-packages/joblib/numpy_pickle.py:650\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    648\u001b[0m         obj \u001b[38;5;241m=\u001b[39m _unpickle(fobj)\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    651\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m fobj:\n\u001b[1;32m    652\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    653\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[1;32m    654\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[1;32m    655\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/glade/campaign/univ/ugit0034/ML4O2_results/algorithm_v1.2.1.1.1.1.sav'"
     ]
    }
   ],
   "source": [
    "dirout='/glade/campaign/univ/ugit0034/ML4O2_results/'\n",
    "MLmodel = joblib.load(dirout+f'algorithm_v{ver}.sav')\n",
    "# read in additional parameters\n",
    "params = np.load(dirout+f'ML_params_v{ver}.npz')\n",
    "Xm=params['Xm']\n",
    "Xstd=params['Xstd']\n",
    "ym=params['ym']\n",
    "ystd=params['ystd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ddb2d5f-260b-402f-bb6d-febc85dd8f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basin mask\n",
    "dsm=xr.open_dataset('/glade/campaign/univ/ugit0034/wod18/basin_mask_01.nc')\n",
    "ma = dsm.basin_mask.sel(depth=Z).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3939be1d-27f1-4385-ad39-fdee3f57faa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "zlev=300\n",
    "kind=[idx for idx,elem in enumerate(Z) if elem==zlev]\n",
    "maz=np.squeeze(ma[kind,:,:])\n",
    "#\n",
    "mon=[\"%.2d\" % i for i in np.arange(1,13,1)]\n",
    "#\n",
    "dc=xr.open_dataset(dirf+'EN4_TSN2_L09_180x360_'+str(1965)+mon[0]+'.nc')\n",
    "y=dc.lat.to_numpy()\n",
    "x=dc.lon.to_numpy()\n",
    "# use alternative x coordinate: longitude - 20\n",
    "xa0 = x - 20\n",
    "xalt = np.where(xa0<0,xa0+360,xa0)\n",
    "#\n",
    "Ny=np.size(y)\n",
    "Nx=np.size(x)\n",
    "Nt=np.size(yrs)*12\n",
    "xx,yy=np.meshgrid(xalt,y)\n",
    "#\n",
    "depth1 = dc.depth.to_numpy()\n",
    "Nz1 = np.size(depth1)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09a2bea6-1f0d-4f24-8831-a4e91137366f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply basin mask \n",
    "def apply_basinmask(datain):\n",
    "    if selection[2] == '1':\n",
    "        dataout=np.where((maz==1),datain,np.nan)\n",
    "    elif selection[2] == '2':\n",
    "        dataout=np.where((maz==2),datain,np.nan)\n",
    "    elif selection[2] == '3':\n",
    "        dataout=np.where((maz==3)&(maz==56),datain,np.nan)\n",
    "    elif selection[2] == '4':\n",
    "        dataout=np.where((maz==10),datain,np.nan)\n",
    "    elif selection[2] == '5':\n",
    "        dataout=np.where((maz==11),datain,np.nan)\n",
    "    else:\n",
    "        print('error - incorrect O2 data type')\n",
    "    #\n",
    "    return dataout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2db04a21-c7d8-450f-9f2b-97a7c68bf7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get input data from full model\n",
    "def get_inputdata(zlev,it,year,mn):\n",
    "    #dc = xr.open_dataset(dirf+'EN4_TSN2_G10_180x360_'+str(year)+mon[mn]+'.nc')\n",
    "    dc = xr.open_dataset(dirf+'EN4_TSN2_L09_180x360_'+str(year)+mon[mn]+'.nc')\n",
    "    soa=dc.SA.interp(depth=zlev).to_numpy().squeeze()\n",
    "    toa=dc.CT.interp(depth=zlev).to_numpy().squeeze()\n",
    "    return soa,toa#,mld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecabb87d-ad12-44a8-af90-7fd74d035e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data matrix\n",
    "def gen_datamatrix(xi,yi,it,x1,x2,x3,x4):\n",
    "    X1 = x1.flatten() # \n",
    "    X2 = x2.flatten() # \n",
    "    X3 = x3.flatten() # \n",
    "    X4 = x4.flatten() # \n",
    "    tt0  = np.ones((Ny,Nx))*it\n",
    "    X5 = tt0.flatten() # decimal year \n",
    "    X6 = X5%12         # month\n",
    "    xxi = xi.flatten() # lon\n",
    "    yyi = yi.flatten() # lat\n",
    "    # \n",
    "    #ml1 = mld.flatten()\n",
    "    #X6 = np.where(ml1>zlev-zoff,X6,2)\n",
    "    # remove nan\n",
    "    #print([np.size(X1),np.size(X2),np.size(X3),np.size(X4),np.size(X5)])\n",
    "    dd = X1+X2+X3+X4+X5\n",
    "    X11=X1[np.isnan(dd)==False]\n",
    "    X21=X2[np.isnan(dd)==False]\n",
    "    X31=X3[np.isnan(dd)==False]\n",
    "    X41=X4[np.isnan(dd)==False]\n",
    "    X51=X5[np.isnan(dd)==False]\n",
    "    X61=X6[np.isnan(dd)==False]\n",
    "    #\n",
    "    Xi=xxi[np.isnan(dd)==False]\n",
    "    Yi=yyi[np.isnan(dd)==False]\n",
    "    #\n",
    "    zin = np.ones(np.size(X11))*zlev\n",
    "    # Normalize data\n",
    "    # generate data matrix and standardize it\n",
    "    X = np.array([X11, X21, X31, X41, zin, X51, X61])\n",
    "    Xa = (X.T - Xm)/Xstd\n",
    "    Nsample = np.size(X11)\n",
    "    #print(Nsample)\n",
    "    return Xa,Xi,Yi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "993d62e2-8b57-4bb5-bc2e-ac09a0ec6da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_yearly(year):\n",
    "    Nx=np.size(x)\n",
    "    Ny=np.size(y)\n",
    "    zlev_arr=np.array([zlev])\n",
    "    o2est2=np.zeros((12,1,Ny,Nx))\n",
    "    xxi,yyi=np.meshgrid(np.arange(0,Nx,1),np.arange(0,Ny,1))\n",
    "    if year%10 == 5:\n",
    "        print('year = '+str(year))\n",
    "    t=np.arange(str(year)+'-01',str(year+1)+'-01',dtype='datetime64[M]')\n",
    "    for month in range(12):\n",
    "        it = month+(year-1965)*12\n",
    "        soa,toa = get_inputdata(zlev,it,year,month)\n",
    "        # apply mask\n",
    "        soa=apply_basinmask(soa)\n",
    "        toa=apply_basinmask(toa)\n",
    "        # generate data matrix\n",
    "        Xa,xi,yi=gen_datamatrix(xxi,yyi,it,soa,toa,xx,yy)\n",
    "        temp = np.shape(Xa)\n",
    "        Nsample=temp[0]\n",
    "        # projection\n",
    "        out = reg.predict(Xa)\n",
    "        # map it back to lon-lat grid\n",
    "        temp = np.nan*np.zeros((Ny,Nx))\n",
    "        for n in range(Nsample):\n",
    "            temp[yi[n],xi[n]]=out[n]\n",
    "        o2est2[month,0,:,:] = temp*ystd + ym\n",
    "    da1=xr.DataArray(data=o2est2,name='o2est',dims=['time','depth','lat','lon'],\n",
    "                 coords={'time':t,'depth':zlev_arr,'lat':yout,'lon':xout})\n",
    "    ds=da1.to_dataset()\n",
    "    ds.to_netcdf(diro+'temp/o2est_'+str(year)+'.nc')\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c369ec40-eb49-46b7-afc5-e6e7cb0192c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating 6.0m\n",
      "year = 1965\n",
      "year = 1975\n",
      "year = 1985\n",
      "year = 1995\n",
      "year = 2005\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "calculating 10.0m\n",
      "year = 1965\n",
      "year = 1975\n",
      "year = 1985\n",
      "year = 1995\n",
      "year = 2005\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "calculating 20.0m\n",
      "year = 1965\n",
      "year = 1975\n",
      "year = 1985\n",
      "year = 1995\n",
      "year = 2005\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "calculating 30.0m\n",
      "year = 1965\n",
      "year = 1975\n",
      "year = 1985\n",
      "year = 1995\n",
      "year = 2005\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "calculating 40.0m\n",
      "year = 1965year = 1975\n",
      "\n",
      "year = 1985\n",
      "year = 1995\n",
      "year = 2005\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "calculating 50.0m\n",
      "year = 1965\n",
      "year = 1975\n",
      "year = 1985\n",
      "year = 1995\n",
      "year = 2005\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "calculating 65.0m\n",
      "year = 1965year = 1975\n",
      "\n",
      "year = 1985\n",
      "year = 1995\n",
      "year = 2005\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "calculating 80.0m\n",
      "year = 1965\n",
      "year = 1975\n",
      "year = 1985\n",
      "year = 1995\n",
      "year = 2005\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "calculating 100.0m\n",
      "year = 1965\n",
      "year = 1975\n",
      "year = 1985\n",
      "year = 1995\n",
      "year = 2005\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "calculating 150.0m\n",
      "year = 1965\n",
      "year = 1975\n",
      "year = 1985\n",
      "year = 1995\n",
      "year = 2005\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "calculating 200.0m\n",
      "year = 1965\n",
      "year = 1975\n",
      "year = 1985\n",
      "year = 1995\n",
      "year = 2005\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "calculating 250.0m\n",
      "year = 1965\n",
      "year = 1975\n",
      "year = 1985\n",
      "year = 1995\n",
      "year = 2005\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "calculating 300.0m\n",
      "year = 1965year = 1975\n",
      "\n",
      "year = 1985\n",
      "year = 1995\n",
      "year = 2005\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "calculating 400.0m\n",
      "year = 1965\n",
      "year = 1975\n",
      "year = 1985\n",
      "year = 1995\n",
      "year = 2005\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "calculating 500.0m\n",
      "year = 1965\n",
      "year = 1975\n",
      "year = 1985\n",
      "year = 1995\n",
      "year = 2005\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "calculating 600.0m\n",
      "year = 1965\n",
      "year = 1975\n",
      "year = 1985\n",
      "year = 1995\n",
      "year = 2005\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "calculating 700.0m\n",
      "year = 1965\n",
      "year = 1975\n",
      "year = 1985\n",
      "year = 1995\n",
      "year = 2005\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "calculating 800.0m\n",
      "year = 1965\n",
      "year = 1975\n",
      "year = 1985\n",
      "year = 1995\n",
      "year = 2005\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "calculating 900.0m\n",
      "year = 1975year = 1965\n",
      "\n",
      "year = 1985\n",
      "year = 1995\n",
      "year = 2005\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "calculating 1000.0m\n",
      "year = 1965\n",
      "year = 1975\n",
      "year = 1985\n",
      "year = 1995\n",
      "year = 2005\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "zlevels = depth1\n",
    "#\n",
    "# reconstruction in parallel mode\n",
    "#\n",
    "reg=MLmodel\n",
    "xout=dc.lon\n",
    "yout=dc.lat\n",
    "#\n",
    "for zlev_cnt,zlev in enumerate(zlevels):\n",
    "    print(f'calculating {zlev}m')\n",
    "    maz = dsm.basin_mask.interp(depth=zlev).to_numpy()\n",
    "    #kind=[idx for idx,elem in enumerate(Z) if elem==zlev]\n",
    "    #maz=np.squeeze(ma[kind,:,:])\n",
    "    os.system('rm '+diro+'/temp/*.nc')\n",
    "    #\n",
    "    if __name__ == '__main__':\n",
    "        with Pool(10) as p:\n",
    "            print(p.map(map_yearly, yrs))\n",
    "    #\n",
    "    # save the result as a netCDF file\n",
    "    #\n",
    "    dtemp=xr.open_mfdataset(diro+'temp/o2est*.nc')\n",
    "    dtemp.to_netcdf(diro+'/O2map_v'+ver+'_z'+str(int(zlev))+'.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8123585-4ee7-4570-b915-aaf4233b1fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=xr.open_mfdataset(f'{diro}O2map_v{ver}*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "918aa4fc-5168-4c64-bcf2-5380909ec71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.system(f'rm {dirout}O2map_v{ver}.nc')\n",
    "ds.to_netcdf(f'{dirout}O2map_v{ver}.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcdb700-84f4-4eb8-b574-d05fb0d2b9ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML4O2_v2",
   "language": "python",
   "name": "ml4o2_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
