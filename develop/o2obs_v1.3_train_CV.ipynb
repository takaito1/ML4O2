{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8faa111e-05ac-4f80-9bee-f601b5bca839",
   "metadata": {},
   "source": [
    "# North Atlantic O2 gapfill\n",
    "    - Version 1.3\n",
    "    - \"isopycnal\" model, no depth information is entered into the ML model\n",
    "    - Omits month below the surface mixed layer\n",
    "    - Absolute magnitude of O2 is estimated as a function of T, S, long, lat, and time (year, month)\n",
    "    - Reads in the data from WOD profiles\n",
    "    - Separates the data into training and test data (75% - 25%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f4841c-2e34-4013-bbc0-a776d4f3d264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import sklearn as skl\n",
    "import gsw\n",
    "import cartopy.crs as ccrs\n",
    "from scipy.interpolate import interp1d\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd6f645-f44d-4719-b953-29a7c85942b1",
   "metadata": {},
   "source": [
    "### First prepare O2, T, S, stratification data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efe3e10-117d-4dab-8aac-b95b56eec428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# version information\n",
    "ver = 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423dfb32-5f0d-4dac-a81e-b79f298992c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# observational data \n",
    "# -------------------------------------------------------------\n",
    "# Needs adjustment: this is where you write out the output files\n",
    "# replace \"ito\" with your username\n",
    "diro = '/glade/scratch/ito/WOD18_OSDCTD/'\n",
    "# -------------------------------------------------------------\n",
    "dirf = '/glade/campaign/univ/ugit0034/EN4/L09_20x180x360/'\n",
    "dirin = '/glade/campaign/univ/ugit0034/WOD18_OSDCTD/'\n",
    "fosd='_1x1bin_osd_'\n",
    "fctd='_1x1bin_ctd_'\n",
    "fmer='_1x1bin_merged_'\n",
    "var=['o2','TSN2']\n",
    "os.system('mkdir -p '+diro)\n",
    "os.system('mkdir -p '+diro+'temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52ae2c3-1449-4f83-8515-909f8cd01c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "dwoa=xr.open_dataset('/glade/campaign/univ/ugit0034/woa18/woa18_all_o00_01.nc',decode_times=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de903739-fc32-4055-a6da-cf1671f163d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basin mask\n",
    "dsm=xr.open_dataset('/glade/campaign/univ/ugit0034/wod18/basin_mask_01.nc')\n",
    "#! cp /glade/work/ito/basin_mask_01.nc /glade/campaign/univ/ugit0034/wod18/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2024504-3ce0-42a4-873a-ed865e925333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain vertical grid\n",
    "ds=xr.open_dataset(dirin+var[0]+fmer+str(1965)+'.nc')\n",
    "Z=ds.depth.to_numpy()\n",
    "Nz=np.size(Z)\n",
    "print(Nz)\n",
    "#\n",
    "# cutoff depth\n",
    "zoff = 100\n",
    "#\n",
    "# select analysis period\n",
    "# do not change the start year from 1965 (this is when Carpenter 1965 established modern Winkler method)\n",
    "yrs=np.arange(1965,2011,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bedd65-fc09-45a7-8b9f-8166b723f3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Obtain TS data from observational gridded dataset\n",
    "#\n",
    "Nyr=np.size(yrs)\n",
    "Nt=Nyr*12\n",
    "mon=[\"%.2d\" % i for i in np.arange(1,13,1)]\n",
    "#\n",
    "o2=np.zeros((Nt,Nz,180,360))\n",
    "t=np.zeros((Nt,Nz,180,360))\n",
    "s=np.zeros((Nt,Nz,180,360))\n",
    "mld=np.zeros((Nyr,12,180,360))\n",
    "#\n",
    "for year in yrs:\n",
    "    ytmp=year%10\n",
    "    if ytmp==0:\n",
    "        print(str(year))\n",
    "    ds=xr.open_dataset(dirin+var[0]+fmer+str(year)+'.nc')\n",
    "    tr=12*(year-1965)\n",
    "    o2[tr:(tr+12),:,:,:]=ds.o2.to_numpy()\n",
    "    #\n",
    "    #option 2. use EN4 for training#\n",
    "    for mn in range(12):\n",
    "        ds = xr.open_dataset(dirf+'EN4_TSN2_L09_180x360_'+str(year)+mon[mn]+'.nc')\n",
    "        s[tr+mn,:,:,:]=ds.SA.interp(depth=Z).to_numpy().squeeze()\n",
    "        t[tr+mn,:,:,:]=ds.CT.interp(depth=Z).to_numpy().squeeze()\n",
    "        mld[year-1965,mn,:,:]=ds.MLD_125.to_numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12814f85-9295-4a3b-9d54-8cc4a4e2eaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mldc=np.mean(mld,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aac25d1-9b17-42ae-b673-4b4d7350279e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get coordinates\n",
    "x=ds.lon.to_numpy()\n",
    "y=ds.lat.to_numpy()\n",
    "xi=np.arange(0,360,1)\n",
    "yi=np.arange(0,180,1)\n",
    "xx,yy=np.meshgrid(x,y)\n",
    "xxi,yyi=np.meshgrid(xi,yi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4bed6a-0dc8-48f7-906c-bb2891e89ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract mask in the Atlantic basin\n",
    "mask= dsm.basin_mask.sel(depth=Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564a09df-a0cc-4026-a467-ad4ffd2efc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at the data\n",
    "fig,ax=plt.subplots(3,2)\n",
    "# select 500m for plotting\n",
    "kind=[idx for idx,elem in enumerate(Z) if elem==500]\n",
    "#\n",
    "mask.isel(depth=kind).plot(ax=ax[0,0],vmin=0,vmax=5,label='basin_mask')\n",
    "ax[0,1].pcolormesh(x,y,np.nanmean(o2[:,kind[0],:,:],axis=0))\n",
    "ax[1,0].pcolormesh(x,y,np.nanmean(s[:,kind[0],:,:],axis=0))\n",
    "ax[1,1].pcolormesh(x,y,np.nanmean(t[:,kind[0],:,:],axis=0))\n",
    "ax[2,0].pcolormesh(x,y,np.nanmean(mldc,axis=0))\n",
    "ax[2,1].remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c4d225-0f7b-4a2e-a8ee-171ce1570434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get basin mask\n",
    "ma = dsm.basin_mask.sel(depth=Z).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39289aa-c053-44b6-9e2a-d07b61cb3dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# climatological mld\n",
    "mldc1 = np.tile(mldc,[Nyr,1,1])\n",
    "mld1 = np.tile(mldc1,[Nz,1,1,1])\n",
    "mld1  = np.transpose(mld1,(1,0,2,3))+zoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01843975-2a4a-4d39-8087-6900b19dacbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make numpy array\n",
    "doa = o2\n",
    "dsa = s\n",
    "dta = t\n",
    "#\n",
    "# prepare depth lat lon time data\n",
    "xx1 = np.tile(xx,[Nt,Nz,1,1])\n",
    "yy1 = np.tile(yy,[Nt,Nz,1,1])\n",
    "ztmp = np.tile(Z,[Nt,180,360,1])\n",
    "zz1 = np.transpose(ztmp,[0,3,1,2])\n",
    "t0=np.arange(0,Nt,1)\n",
    "t1=t0%12\n",
    "#\n",
    "tt0 = np.tile(t0,[Nz,180,360,1])\n",
    "tt1 = np.transpose(tt0,(3,0,1,2))\n",
    "tc0 = np.tile(t1,[Nz,180,360,1])\n",
    "tc1 = np.transpose(tc0,(3,0,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0b0a75-5788-4ecc-a818-e33f26db44a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------\n",
    "#  apply mask \n",
    "#  basin mask is 1 for Atlantic, 2 for Pacific\n",
    "# ----------------------------------\n",
    "doa=np.where((ma==1)&(yy>0),doa,np.nan)\n",
    "dsa=np.where((ma==1)&(yy>0),dsa,np.nan)\n",
    "dta=np.where((ma==1)&(yy>0),dta,np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0441109-8d8b-4dbd-ba2d-79540ec57723",
   "metadata": {},
   "source": [
    "### Now we have the data for the North Atlantic. Remove NaNs and organize them into 1d array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fb24af-90a1-4d89-ae17-e0c0b64b589d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data vector\n",
    "doa0 = doa.flatten()\n",
    "dsa0 = dsa.flatten()\n",
    "dta0 = dta.flatten()\n",
    "xx0  = xx1.flatten()\n",
    "yy0  = yy1.flatten()\n",
    "tt0  = tt1.flatten()\n",
    "tc0  = tc1.flatten()\n",
    "zz0  = zz1.flatten()\n",
    "ml0  = mld1.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b90748a-7809-4d62-b5c5-3c809cac4a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove nan\n",
    "dd = doa0 + dsa0 + dta0\n",
    "doa1=doa0[np.isnan(dd)==False]\n",
    "dsa1=dsa0[np.isnan(dd)==False]\n",
    "dta1=dta0[np.isnan(dd)==False]\n",
    "xx1=xx0[np.isnan(dd)==False]\n",
    "yy1=yy0[np.isnan(dd)==False]\n",
    "zz1=zz0[np.isnan(dd)==False]\n",
    "tt1=tt0[np.isnan(dd)==False]\n",
    "tc1=tc0[np.isnan(dd)==False]\n",
    "ml1=ml0[np.isnan(dd)==False]\n",
    "# clim MLD + cutoff, deeper layer is set to 2 = March\n",
    "tc1=np.where(zz1<ml1,tc1,2)\n",
    "#\n",
    "Nsample = np.size(doa1)\n",
    "print(Nsample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2687e2e3-71f2-4faf-bd44-c3b573406f2b",
   "metadata": {},
   "source": [
    "### This is where we choose what variables to include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b30889-4104-489c-8dbe-e6230ec17598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data matrix and standardize it\n",
    "X = np.array([dsa1, dta1, xx1, yy1, tt1, tc1])\n",
    "#X = np.array([dsa1, dta1, xx1, yy1, zz1, tt1, tc1])\n",
    "y = doa1\n",
    "#\n",
    "Xm = np.mean(X,axis=1)\n",
    "Xstd = np.std(X,axis=1)\n",
    "#\n",
    "N=np.size(y)\n",
    "# normalize x and y\n",
    "Xa = (X.T - Xm)/Xstd\n",
    "ym = np.mean(y)\n",
    "ystd = np.std(y)\n",
    "ya = (y-ym)/ystd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c2cd24-e662-4fd4-86db-0d1faefd32ab",
   "metadata": {},
   "source": [
    "## ML\n",
    "\n",
    "### First split the data into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d810445a-4913-4bfe-ba00-6c28f428606c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xa, ya)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa272135-40d3-45e1-91d2-594a93fdec5c",
   "metadata": {},
   "source": [
    "### Random Forest Regressor (RFregr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dc555d-1be2-4578-9fea-64196e1d87e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## RF\n",
    "##\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6587f05-8042-41ec-bf37-1de51602f943",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFregr = RandomForestRegressor()\n",
    "#RFregr.fit(X_train, y_train)\n",
    "clf=RandomForestRegressor(n_jobs=10)\n",
    "parameters = {'n_estimators':[500],'min_samples_leaf':[12],'max_features':[3]}\n",
    "RFregr = GridSearchCV(clf, parameters)\n",
    "RFregr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c365eea-bebe-4407-a07f-21da5e23f192",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFregr.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ddae2e-1390-434e-9692-60963927a258",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = RFregr.predict(X_test)\n",
    "RFregr.score(X_test, y_test)\n",
    "#RFregr.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1966de2a-a16f-46f7-8e47-f856cdf77ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "o2est = out*ystd + ym\n",
    "o2test= y_test*ystd + ym\n",
    "#\n",
    "plt.plot(o2test,o2est,'k.',markersize=.3)\n",
    "plt.plot([0,400],[0,400])\n",
    "plt.ylabel('O2 prediction, micro-mol/kg')\n",
    "plt.xlabel('O2 test data, micro-mol/kg')\n",
    "temp=np.corrcoef(o2est,o2test)\n",
    "Rval_RF=temp[0,1]\n",
    "print('R2 = ',Rval_RF**2)\n",
    "RMSE_RF=np.sqrt(np.mean((o2est-o2test)**2))\n",
    "print('RMSE = ',RMSE_RF)\n",
    "#\n",
    "o2test_RF = o2test.copy()\n",
    "o2est_RF = o2est.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4efa742-be89-44e7-8302-72b8be91a407",
   "metadata": {},
   "source": [
    "### Neural Network estimator (NNregr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7126222f-5f18-4be2-adb9-ee05efab5be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NN\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545e2224-b9e1-498b-8dea-6c3020700b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NNregr = MLPRegressor(hidden_layer_sizes=(10,10,10,10),alpha=0.01, \n",
    "#                      random_state=1, max_iter=1000).fit(X_train, y_train)\n",
    "clf=MLPRegressor(max_iter=1000)\n",
    "parameters = {'hidden_layer_sizes':[[10,10,10,10]],'alpha':[.01]}\n",
    "NNregr = GridSearchCV(clf, parameters)\n",
    "NNregr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c59a22-b7df-4fc5-9dc7-385237712be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "NNregr.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4446664-0699-4c45-bb6a-87f63cc22306",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = NNregr.predict(X_test)\n",
    "NNregr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7564b1-f15a-4474-a0b3-4879b2e9f9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "o2est = out*ystd + ym\n",
    "o2test= y_test*ystd + ym\n",
    "#\n",
    "plt.plot(o2test,o2est,'k.',markersize=.3)\n",
    "plt.plot([0,400],[0,400])\n",
    "plt.ylabel('O2 prediction, micro-mol/kg')\n",
    "plt.xlabel('O2 test data, micro-mol/kg')\n",
    "temp=np.corrcoef(o2est,o2test)\n",
    "Rval_NN=temp[0,1]\n",
    "print('correlation = ',Rval_NN)\n",
    "RMSE_NN=np.sqrt(np.mean((o2est-o2test)**2))\n",
    "print('RMSE = ',RMSE_NN)\n",
    "o2test_NN = o2test.copy()\n",
    "o2est_NN = o2est.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edf0b3e-93fd-4559-b262-428febd595f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# Uncomment the line below to save the final version\n",
    "# ---------------------------------------------------\n",
    "import joblib\n",
    "# comment these out if you don't want to save the results\n",
    "np.savez(f'ML_params_v{ver}.npz',Xm=Xm,Xstd=Xstd,ym=ym,ystd=ystd)\n",
    "#\n",
    "filename = f'NN_model_v{ver}.sav'\n",
    "joblib.dump(NNregr, filename)\n",
    "#\n",
    "filename = f'RF_model_v{ver}.sav'\n",
    "joblib.dump(RFregr, filename)\n",
    "#\n",
    "np.save('mldc.npy',mldc)\n",
    "np.savez(f'o2test_pred_v{ver}.npz',Xtest=X_test,NNtest=o2test_NN,NNest=o2est_NN,RFtest=o2test_RF,RFest=o2est_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcfc72d-a17c-4985-a756-6831cfedae20",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFregr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d9f325-7981-475c-8da3-538c18844ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML4O2_v2",
   "language": "python",
   "name": "ml4o2_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
